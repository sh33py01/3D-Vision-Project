{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare ShapeNet Data:\n",
    "Download ShapeNet point clouds or convert from meshes using tools like trimesh\n",
    "Save each point cloud as a .npy file in a structured directory\n",
    "\n",
    "Training:\n",
    "Update \"path_to_shapenet_point_clouds\" in the dataset initialization\n",
    "Run train_point_cloud_gan()\n",
    "Monitor losses and visualize generated samples\n",
    "\n",
    "Generation:\n",
    "After training, load the generator:\n",
    "////\n",
    "generator = Generator().to(device)\n",
    "generator.load_state_dict(torch.load(\"generator.pth\"))\n",
    "Generate new point clouds:\n",
    "///\n",
    "z = torch.randn(1, latent_dim).to(device)\n",
    "new_pc = generator(z).cpu().numpy()[0]\n",
    "visualize_point_cloud(new_pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import open3d as o3d\n",
    "import torch.nn as nn\n",
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install POT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database conversion\n",
    "The original dataset contains files in .off file format, which is incompatible with the subsequent code.\\\n",
    "This chunk of code converts them into .npy file format, compatible with the subsequent code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gloabl Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "generator = None\n",
    "latent_dim = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_point_cloud(points, filename):\n",
    "    \"\"\" Save point cloud to PLY file \"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    o3d.io.write_point_cloud(filename, pcd)\n",
    "\n",
    "def visualize_point_cloud(points):\n",
    "    \"\"\" Interactive visualization \"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self, root_dir, num_points=2048, split='train'):\n",
    "        self.root_dir = root_dir\n",
    "        self.num_points = num_points\n",
    "        self.files = []\n",
    "        \n",
    "        if not os.path.exists(root_dir):\n",
    "            raise ValueError(f\"Directory {root_dir} does not exist\")\n",
    "            \n",
    "        for class_dir in os.listdir(root_dir):\n",
    "            class_path = os.path.join(root_dir, class_dir)\n",
    "            if os.path.isdir(class_path):\n",
    "                for file in os.listdir(class_path):\n",
    "                    if file.endswith('.npy'):\n",
    "                        self.files.append(os.path.join(class_path, file))\n",
    "        \n",
    "        if len(self.files) == 0:\n",
    "            raise ValueError(f\"No .npy files found in {root_dir}\")\n",
    "\n",
    "        split_idx = int(0.8 * len(self.files))\n",
    "        self.files = self.files[:split_idx] if split == 'train' else self.files[split_idx:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            pc = np.load(self.files[idx], allow_pickle=True)\n",
    "\n",
    "            if pc.shape[0] > self.num_points:\n",
    "                idxs = np.random.choice(pc.shape[0], self.num_points, replace=False)\n",
    "                pc = pc[idxs]\n",
    "            elif pc.shape[0] < self.num_points:\n",
    "                idxs = np.random.choice(pc.shape[0], self.num_points, replace=True)\n",
    "                pc = pc[idxs]\n",
    "\n",
    "            pc = torch.from_numpy(pc).float()\n",
    "            pc = self.normalize_point_cloud(pc)\n",
    "            return pc\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading index {idx}, file: {self.files[idx]}\")\n",
    "            print(f\"Exception: {e}\")\n",
    "            return torch.zeros((self.num_points, 3))  # or raise the error again \n",
    "\n",
    "    def normalize_point_cloud(self, pc):\n",
    "        \"\"\" Normalize point cloud to fit in [-1, 1] cube \"\"\"\n",
    "        centroid = torch.mean(pc, dim=0)\n",
    "        pc = pc - centroid\n",
    "        max_dist = torch.max(torch.sqrt(torch.sum(pc**2, dim=1)))\n",
    "        pc = pc / max_dist\n",
    "        return pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Definitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, num_points):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_points = num_points\n",
    "        \n",
    "        # Fully connected layers with batch norm and leaky ReLU\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # Final layer outputs 3D coordinates (x,y,z) for each point\n",
    "            nn.Linear(2048, num_points * 3),\n",
    "            nn.Tanh()  # Tanh keeps outputs in [-1,1] range\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        batch_size = z.size(0)\n",
    "        # Generate point cloud\n",
    "        pc = self.model(z)\n",
    "        # Reshape to [batch_size, num_points, 3]\n",
    "        pc = pc.view(batch_size, self.num_points, 3)\n",
    "        return pc\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_points=2048):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.num_points = num_points\n",
    "        \n",
    "        # Shared MLP layers (similar to PointNet)\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)  # Input channels: 3 (x,y,z), output: 64\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 256, 1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        # Global feature layer\n",
    "        self.global_conv = nn.Conv1d(256, 512, 1)\n",
    "        self.global_bn = nn.BatchNorm1d(512)\n",
    "        \n",
    "        # Classification layers\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, num_points, 3)\n",
    "        x = x.transpose(2, 1)  # Convert to (batch_size, 3, num_points)\n",
    "        \n",
    "        # Shared MLP\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        # Global features\n",
    "        x = self.relu(self.global_bn(self.global_conv(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]  # Global max pooling\n",
    "        x = x.view(-1, 512)\n",
    "        \n",
    "        # Classification\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(discriminator, real_samples, fake_samples, device):\n",
    "    \"\"\" Calculates the gradient penalty loss for WGAN-GP \"\"\"\n",
    "    batch_size = real_samples.size(0)\n",
    "    # Random weight term for interpolation\n",
    "    alpha = torch.rand(batch_size, 1, 1).to(device)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    \n",
    "    d_interpolates = discriminator(interpolates)\n",
    "    fake = torch.ones(batch_size, 1).to(device)\n",
    "    \n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.reshape(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chamfer_distance(pc1, pc2):\n",
    "    \"\"\"Compute Chamfer Distance between two point clouds\"\"\"\n",
    "    dist = cdist(pc1, pc2)\n",
    "    return np.mean(np.min(dist, axis=0)) + np.mean(np.min(dist, axis=1))\n",
    "\n",
    "def earth_movers_distance(pc1, pc2):\n",
    "    \"\"\"Approximate EMD using the Sinkhorn algorithm\"\"\"\n",
    "    from ot import emd\n",
    "    # Normalize to probability distributions\n",
    "    pc1 = pc1 / np.sum(pc1, axis=1, keepdims=True)\n",
    "    pc2 = pc2 / np.sum(pc2, axis=1, keepdims=True)\n",
    "    cost_matrix = cdist(pc1, pc2)\n",
    "    return emd([], [], cost_matrix)\n",
    "\n",
    "def evaluate_model(generator, latent_dim, real_dataset, num_samples=100, device='cuda'):\n",
    "    \"\"\"Comprehensive evaluation of generated samples\"\"\"\n",
    "    generator.eval()\n",
    "    \n",
    "    # Generate samples\n",
    "    fake_pcs = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_samples):\n",
    "            z = torch.randn(1, latent_dim).to(device)\n",
    "            fake_pc = generator(z).cpu().numpy()[0]\n",
    "            fake_pcs.append(fake_pc)\n",
    "    \n",
    "    # Get real samples\n",
    "    real_pcs = [real_dataset[i].numpy() for i in range(num_samples)]\n",
    "    \n",
    "    # Compute metrics\n",
    "    cd_scores, emd_scores = [], []\n",
    "    for real_pc, fake_pc in zip(real_pcs, fake_pcs):\n",
    "        cd_scores.append(chamfer_distance(real_pc, fake_pc))\n",
    "        emd_scores.append(earth_movers_distance(real_pc, fake_pc))\n",
    "    \n",
    "    return {\n",
    "        'chamfer_distance': np.mean(cd_scores),\n",
    "        'earth_movers_distance': np.mean(emd_scores),\n",
    "        'samples': (real_pcs, fake_pcs)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_comparison(real_pc, fake_pc, save_path=None):\n",
    "    \"\"\"Visualize real vs generated point clouds side by side\"\"\"\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Real point cloud\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax1.scatter(real_pc[:,0], real_pc[:,1], real_pc[:,2], s=1)\n",
    "    ax1.set_title('Real Point Cloud')\n",
    "    ax1.set_axis_off()\n",
    "    \n",
    "    # Generated point cloud\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    ax2.scatter(fake_pc[:,0], fake_pc[:,1], fake_pc[:,2], s=1)\n",
    "    ax2.set_title('Generated Point Cloud')\n",
    "    ax2.set_axis_off()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def generate_and_save_samples(generator, latent_dim, num_samples=5, device='cuda'):\n",
    "    \"\"\"Generate and save sample point clouds\"\"\"\n",
    "    generator.eval()\n",
    "    os.makedirs('samples', exist_ok=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            z = torch.randn(1, latent_dim).to(device)\n",
    "            pc = generator(z).cpu().numpy()[0]\n",
    "            \n",
    "            # Save as PLY and PNG\n",
    "            save_path = f'samples/sample_{i}'\n",
    "            save_point_cloud(pc, f'{save_path}.ply')\n",
    "            \n",
    "            # Create visualization\n",
    "            fig = plt.figure(figsize=(6,6))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            ax.scatter(pc[:,0], pc[:,1], pc[:,2], s=1)\n",
    "            ax.set_axis_off()\n",
    "            plt.savefig(f'{save_path}.png', bbox_inches='tight', dpi=150)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-Training Analysis Script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(generator, latent_dim, run_dir='results'):\n",
    "    \"\"\"Analyze and visualize training results\"\"\"\n",
    "    # 1. Plot training curves (would need to modify to log losses)\n",
    "    # plot_training_curves(run_dir)\n",
    "    \n",
    "    # 2. Create interpolation video\n",
    "    create_interpolation_video(generator, latent_dim)\n",
    "    \n",
    "    # 3. Create HTML visualization\n",
    "    generate_html_viewer(run_dir)\n",
    "\n",
    "def plot_training_curves(run_dir):\n",
    "    \"\"\"Plot loss and metric curves\"\"\"\n",
    "    # Implement reading from log files and plotting\n",
    "    pass\n",
    "\n",
    "def create_interpolation_video(generator, latent_dim, num_frames=60):\n",
    "    \"\"\"Create interpolation between random points in latent space\"\"\"\n",
    "    z1 = torch.randn(1, latent_dim)\n",
    "    z2 = torch.randn(1, latent_dim)\n",
    "    \n",
    "    os.makedirs('interpolation', exist_ok=True)\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        alpha = i / num_frames\n",
    "        z = alpha * z1 + (1-alpha) * z2\n",
    "        pc = generator(z).cpu().numpy()[0]\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(pc[:,0], pc[:,1], pc[:,2], s=1)\n",
    "        plt.savefig(f'interpolation/frame_{i:03d}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Use ffmpeg to create video\n",
    "    os.system('ffmpeg -r 30 -i interpolation/frame_%03d.png -vcodec libx264 -crf 25 interpolation.mp4')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Enhanced Evaluation Metrics Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def chamfer_distance(pc1, pc2):\n",
    "    \"\"\"Compute Chamfer Distance between two point clouds\"\"\"\n",
    "    dist = cdist(pc1, pc2)\n",
    "    return np.mean(np.min(dist, axis=0)) + np.mean(np.min(dist, axis=1))\n",
    "\n",
    "def earth_movers_distance(pc1, pc2):\n",
    "    \"\"\"Approximate EMD using the Sinkhorn algorithm\"\"\"\n",
    "    from ot import emd\n",
    "    # Normalize to probability distributions\n",
    "    pc1 = pc1 / np.sum(pc1, axis=1, keepdims=True)\n",
    "    pc2 = pc2 / np.sum(pc2, axis=1, keepdims=True)\n",
    "    cost_matrix = cdist(pc1, pc2)\n",
    "    return emd([], [], cost_matrix)\n",
    "\n",
    "def evaluate_model(generator, latent_dim, real_dataset, num_samples=100, device='cuda'):\n",
    "    \"\"\"Comprehensive evaluation of generated samples\"\"\"\n",
    "    generator.eval()\n",
    "    \n",
    "    # Generate samples\n",
    "    fake_pcs = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_samples):\n",
    "            z = torch.randn(1, latent_dim).to(device)\n",
    "            fake_pc = generator(z).cpu().numpy()[0]\n",
    "            fake_pcs.append(fake_pc)\n",
    "    \n",
    "    # Get real samples\n",
    "    real_pcs = [real_dataset[i].numpy() for i in range(num_samples)]\n",
    "    \n",
    "    # Compute metrics\n",
    "    cd_scores, emd_scores = [], []\n",
    "    for real_pc, fake_pc in zip(real_pcs, fake_pcs):\n",
    "        cd_scores.append(chamfer_distance(real_pc, fake_pc))\n",
    "        emd_scores.append(earth_movers_distance(real_pc, fake_pc))\n",
    "    \n",
    "    return {\n",
    "        'chamfer_distance': np.mean(cd_scores),\n",
    "        'earth_movers_distance': np.mean(emd_scores),\n",
    "        'samples': (real_pcs, fake_pcs)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_point_cloud_gan():\n",
    "    global global_generator, global_latent_dim \n",
    "    # Hyperparameters\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    global_latent_dim = 62\n",
    "    num_points = 2048\n",
    "    batch_size = 16\n",
    "    epochs = 5\n",
    "    lr = 0.02\n",
    "    n_critic = 3\n",
    "    lambda_gp = 7\n",
    "    \n",
    "    # Debug setup\n",
    "    import gc\n",
    "    def print_memory():\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU Memory: {torch.cuda.memory_allocated()/1e9:.2f}GB / {torch.cuda.memory_reserved()/1e9:.2f}GB\")\n",
    "        gc.collect()\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    try:\n",
    "        dataset = PointCloudDataset(\"C:/Users/Edoardo/Desktop/LAb/unpacked_modelnet10/chair\", num_points=num_points)\n",
    "        eval_dataset = PointCloudDataset(\"C:/Users/Edoardo/Desktop/LAb/unpacked_modelnet10/chair\", num_points=num_points, split='test')\n",
    "        print(f\"Dataset loaded with {len(dataset)} samples (train), {len(eval_dataset)} samples (test)\")\n",
    "\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        print(f\"Dataloader created with {len(dataloader)} batches of size {batch_size}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing data: {e}\")\n",
    "        return\n",
    "\n",
    "    # Initialize networks\n",
    "    global_generator = Generator(global_latent_dim, num_points).to(device)\n",
    "    discriminator = Discriminator(num_points).to(device)\n",
    "    global_generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    # Optimizers\n",
    "    optimizer_G = torch.optim.Adam(global_generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Training loop with enhanced monitoring\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\n--- Starting Epoch {epoch+1}/{epochs} ---\")\n",
    "            print_memory()\n",
    "            \n",
    "            for i, real_pcs in enumerate(tqdm(dataloader)):\n",
    "                # Skip any problematic batches\n",
    "                if real_pcs.size(0) != batch_size:\n",
    "                    print(f\"\\nSkipping incomplete batch of size {real_pcs.size(0)}\")\n",
    "                    continue\n",
    "                    \n",
    "                real_pcs = real_pcs.to(device)\n",
    "                \n",
    "                # Train Discriminator\n",
    "                optimizer_D.zero_grad()\n",
    "                \n",
    "                # Generate fake point clouds\n",
    "                z = torch.randn(batch_size, global_latent_dim).to(device)\n",
    "                fake_pcs = global_generator(z)\n",
    "                \n",
    "                # Real and fake losses\n",
    "                real_loss = -torch.mean(discriminator(real_pcs))\n",
    "                fake_loss = torch.mean(discriminator(fake_pcs.detach()))\n",
    "                \n",
    "                # Gradient penalty\n",
    "                gp = gradient_penalty(discriminator, real_pcs.data, fake_pcs.data, device)\n",
    "                \n",
    "                # Total discriminator loss\n",
    "                d_loss = real_loss + fake_loss + lambda_gp * gp\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "                \n",
    "                # Train Generator every n_critic steps\n",
    "                if i % n_critic == 0:\n",
    "                    optimizer_G.zero_grad()\n",
    "                    z = torch.randn(batch_size, global_latent_dim).to(device)\n",
    "                    fake_pcs = global_generator(z)\n",
    "                    g_loss = -torch.mean(discriminator(fake_pcs))\n",
    "                    g_loss.backward()\n",
    "                    optimizer_G.step()\n",
    "                \n",
    "                # Memory monitoring\n",
    "                if i % 10 == 0:\n",
    "                    print_memory()\n",
    "            \n",
    "            # Epoch summary\n",
    "            print(f\"[Epoch {epoch}/{epochs}] D loss: {d_loss.item():.4f}, G loss: {g_loss.item():.4f}\")\n",
    "            \n",
    "            # Evaluation and visualization every 5 epochs\n",
    "            if epoch % 5 == 0 or epoch == epochs - 1:\n",
    "                # Save checkpoint\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'generator': generator.state_dict(),\n",
    "                    'discriminator': discriminator.state_dict(),\n",
    "                    'optimizer_G': optimizer_G.state_dict(),\n",
    "                    'optimizer_D': optimizer_D.state_dict(),\n",
    "                }, f\"checkpoint_epoch_{epoch}.pth\")\n",
    "                print(f\"Saved checkpoint at epoch {epoch}\")\n",
    "                \n",
    "                # Evaluation\n",
    "                metrics = evaluate_model(generator, latent_dim, eval_dataset, \n",
    "                                      num_samples=50, device=device)\n",
    "                \n",
    "                print(f\"\\nEpoch {epoch} Evaluation:\")\n",
    "                print(f\"Chamfer Distance: {metrics['chamfer_distance']:.4f}\")\n",
    "                print(f\"Earth Movers Distance: {metrics['earth_movers_distance']:.4f}\")\n",
    "                \n",
    "                # Visualize samples\n",
    "                real_sample, fake_sample = metrics['samples'][0][0], metrics['samples'][1][0]\n",
    "                visualize_comparison(real_sample, fake_sample, \n",
    "                                   save_path=f\"results/epoch_{epoch}_comparison.png\")\n",
    "                \n",
    "                # Save samples\n",
    "                generate_and_save_samples(generator, latent_dim, num_samples=5, device=device)\n",
    "                \n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        print(\"\\nCUDA out of memory! Try:\")\n",
    "        print(f\"- Reducing batch size (currently {batch_size})\")\n",
    "        print(f\"- Using fewer points (currently {num_points})\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"\\nTraining interrupted by {type(e).__name__}: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "\n",
    "    # Final sample generation and analysis\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            global_generator.eval()\n",
    "            # Save final sample\n",
    "            sample_z = torch.randn(1, global_latent_dim).to(device)\n",
    "            sample_pc = global_generator(sample_z).cpu().numpy()\n",
    "            save_point_cloud(sample_pc[0], \"final_sample.ply\")\n",
    "            print(\"Saved final sample\")\n",
    "            \n",
    "            # Generate analysis - now using global variables\n",
    "            analyze_results(global_generator, global_latent_dim)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in final generation: {e}\")\n",
    "\n",
    "    print(\"\\nTraining completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Execution Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with 791 samples (train), 198 samples (test)\n",
      "Dataloader created with 49 batches of size 16\n",
      "\n",
      "--- Starting Epoch 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/49 [00:30<07:53, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training manually stopped\n",
      "Cleanup complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create necessary directories\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    os.makedirs(\"samples\", exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        train_point_cloud_gan()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTraining manually stopped\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nFatal error in main execution: {type(e).__name__}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        print(\"Cleanup complete\")\n",
    "        #tq3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(run_dir='results'):\n",
    "    \"\"\"Analyze and visualize training results\"\"\"\n",
    "    # 1. Plot training curves\n",
    "    plot_training_curves(run_dir)\n",
    "    \n",
    "    # 2. Generate interpolation video\n",
    "    create_interpolation_video(generator, latent_dim)\n",
    "    \n",
    "    # 3. Create HTML visualization\n",
    "    generate_html_viewer(run_dir)\n",
    "\n",
    "def plot_training_curves(run_dir):\n",
    "    \"\"\"Plot loss and metric curves\"\"\"\n",
    "    # Implement reading from log files and plotting\n",
    "    pass\n",
    "\n",
    "def create_interpolation_video(generator, latent_dim, num_frames=60):\n",
    "    \"\"\"Create interpolation between random points in latent space\"\"\"\n",
    "    z1 = torch.randn(1, latent_dim)\n",
    "    z2 = torch.randn(1, latent_dim)\n",
    "    \n",
    "    os.makedirs('interpolation', exist_ok=True)\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        alpha = i / num_frames\n",
    "        z = alpha * z1 + (1-alpha) * z2\n",
    "        pc = generator(z).cpu().numpy()[0]\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(pc[:,0], pc[:,1], pc[:,2], s=1)\n",
    "        plt.savefig(f'interpolation/frame_{i:03d}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Use ffmpeg to create video\n",
    "    os.system('ffmpeg -r 30 -i interpolation/frame_%03d.png -vcodec libx264 -crf 25 interpolation.mp4')\n",
    "\n",
    "def generate_html_viewer(run_dir):\n",
    "    \"\"\"Create simple HTML viewer for generated samples\"\"\"\n",
    "    html_content = \"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>3D GAN Results</title>\n",
    "        <style>\n",
    "            .sample-container { display: flex; flex-wrap: wrap; }\n",
    "            .sample { margin: 10px; text-align: center; }\n",
    "            img { max-width: 300px; }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Generated 3D Samples</h1>\n",
    "        <div class=\"sample-container\">\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find all sample images\n",
    "    sample_files = [f for f in os.listdir('samples') if f.endswith('.png')]\n",
    "    \n",
    "    for sample in sample_files:\n",
    "        base_name = sample.replace('.png', '')\n",
    "        html_content += f\"\"\"\n",
    "        <div class=\"sample\">\n",
    "            <h3>{base_name}</h3>\n",
    "            <img src=\"samples/{sample}\" alt=\"{base_name}\">\n",
    "            <p><a href=\"samples/{base_name}.ply\">Download PLY</a></p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(f'{run_dir}/viewer.html', 'w') as f:\n",
    "        f.write(html_content)\n",
    "    print(f\"Created HTML viewer at {run_dir}/viewer.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
